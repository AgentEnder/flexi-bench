"use strict";(self.webpackChunk_flexi_bench_docs_site=self.webpackChunk_flexi_bench_docs_site||[]).push([[9175],{1050:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>i,contentTitle:()=>s,default:()=>p,frontMatter:()=>a,metadata:()=>c,toc:()=>m});var o=n(2540),t=n(3023);const a={id:"performance-observer",title:"Performance Observer",sidebar_label:"Performance Observer",description:"FlexiBench provides a `.withPerformanceObserver()` method to easily capture performance of segments of the callback function.\nThis example demonstrates how to use the Performance Observer to capture performance of the `createProjectGraphAsync` function.\nBecause `nx` uses `performance.mark` and `performance.measure` within its codebase, we can easily debug which portion has slowed down.\n\nNote: A performance observer can not capture performance of code running via child processes, so it only works for callback functions.\n",hide_title:!0},s="Performance Observer",c={id:"examples/performance-observer",title:"Performance Observer",description:"FlexiBench provides a `.withPerformanceObserver()` method to easily capture performance of segments of the callback function.\nThis example demonstrates how to use the Performance Observer to capture performance of the \\`createProjectGraphAsync\\` function.\nBecause `nx` uses `performance.mark` and `performance.measure` within its codebase, we can easily debug which portion has slowed down.\n\nNote: A performance observer can not capture performance of code running via child processes, so it only works for callback functions.\n",source:"@site/docs/examples/performance-observer.md",sourceDirName:"examples",slug:"/examples/performance-observer",permalink:"/flexi-bench/examples/performance-observer",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"performance-observer",title:"Performance Observer",sidebar_label:"Performance Observer",description:"FlexiBench provides a `.withPerformanceObserver()` method to easily capture performance of segments of the callback function.\nThis example demonstrates how to use the Performance Observer to capture performance of the \\`createProjectGraphAsync\\` function.\nBecause `nx` uses `performance.mark` and `performance.measure` within its codebase, we can easily debug which portion has slowed down.\n\nNote: A performance observer can not capture performance of code running via child processes, so it only works for callback functions.\n",hide_title:!0},sidebar:"tutorialSidebar",previous:{title:"Failing Actions",permalink:"/flexi-bench/examples/failing-actions"},next:{title:"Runner API",permalink:"/flexi-bench/examples/runner-api"}},i={},m=[];function l(e){const r={code:"code",h1:"h1",p:"p",pre:"pre",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(r.h1,{id:"performance-observer",children:"Performance Observer"}),"\n",(0,o.jsxs)(r.p,{children:["FlexiBench provides a ",(0,o.jsx)(r.code,{children:".withPerformanceObserver()"})," method to easily capture performance of segments of the callback function.\nThis example demonstrates how to use the Performance Observer to capture performance of the `createProjectGraphAsync` function.\nBecause ",(0,o.jsx)(r.code,{children:"nx"})," uses ",(0,o.jsx)(r.code,{children:"performance.mark"})," and ",(0,o.jsx)(r.code,{children:"performance.measure"})," within its codebase, we can easily debug which portion has slowed down."]}),"\n",(0,o.jsx)(r.p,{children:"Note: A performance observer can not capture performance of code running via child processes, so it only works for callback functions."}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-ts",metastring:'title="Performance Observer" showLineNumbers',children:"import { createProjectGraphAsync } from '@nx/devkit';\nimport { daemonClient } from 'nx/src/daemon/client/client';\n\nimport {\n  Benchmark,\n  BenchmarkConsoleReporter,\n  MarkdownBenchmarkReporter,\n} from 'flexi-bench';\nimport { join } from 'path';\n\nconst defaultReporter = new BenchmarkConsoleReporter();\nconst markdownReporter = new MarkdownBenchmarkReporter({\n  outputFile: join(__dirname, 'performance-observer.results.md'),\n  fields: ['average', 'p95'],\n});\n\n(async () => {\n  await new Benchmark('Performance Observer Demo', {\n    iterations: 5,\n    action: async () => {\n      // The createProjectGraphAsync isn't tolerable to how we reset\n      // the daemon client, so without this delay, the graph construction\n      // will fail.\n      await new Promise((r) => setImmediate(r));\n      await createProjectGraphAsync();\n    },\n    reporter: {\n      progress: defaultReporter.progress.bind(defaultReporter),\n      report: markdownReporter.report.bind(markdownReporter),\n    },\n  })\n    .withPerformanceObserver({\n      label: (name) => name.replace(/.*\\/node_modules\\/nx\\/src\\/plugins/, 'nx'),\n    })\n    .withVariation('With Daemon', (v) =>\n      v\n        // Nx read's the NX_DAEMON environment variable to determine\n        // whether or not to use the daemon when the daemon client is\n        // initialized. This is a way to reset the daemon client to\n        // force Nx to reread the environment variable.\n        .withSetup(() => daemonClient.reset())\n        .withEnvironmentVariable('NX_DAEMON', 'true'),\n    )\n    .withVariation('Without Daemon', (v) =>\n      v\n        .withSetup(() => daemonClient.reset())\n        .withEnvironmentVariable('NX_DAEMON', 'false'),\n    )\n    .run();\n  process.exit(0);\n})();\n\n"})})]})}function p(e={}){const{wrapper:r}={...(0,t.R)(),...e.components};return r?(0,o.jsx)(r,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},3023:(e,r,n)=>{n.d(r,{R:()=>s,x:()=>c});var o=n(3696);const t={},a=o.createContext(t);function s(e){const r=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function c(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),o.createElement(a.Provider,{value:r},e.children)}}}]);