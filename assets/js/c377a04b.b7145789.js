"use strict";(self.webpackChunk_flexi_bench_docs_site=self.webpackChunk_flexi_bench_docs_site||[]).push([[3361],{7445:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>h});var i=a(2540),t=a(3023);const r={id:"index",title:"Home",hide_title:!0,slug:"/",sidebar_position:1},c="FlexiBench",s={id:"index",title:"Home",description:"FlexiBench is a flexible benchmarking library for JavaScript and TypeScript. It is designed to be simple to use, but also powerful and flexible. It is inspired by common testing framework APIs, and aims to provide a similar experience for benchmarking.",source:"@site/docs/index.md",sourceDirName:".",slug:"/",permalink:"/flexi-bench/",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"index",title:"Home",hide_title:!0,slug:"/",sidebar_position:1},sidebar:"tutorialSidebar",next:{title:"Changelog",permalink:"/flexi-bench/changelog"}},o={},h=[{value:"Installation",id:"installation",level:2},{value:"Features",id:"features",level:2},{value:"Usage",id:"usage",level:2},{value:"Runner API",id:"runner-api",level:3},{value:"Basic Benchmarks",id:"basic-benchmarks",level:3},{value:"Setup and Teardown",id:"setup-and-teardown",level:4},{value:"Understanding Actions",id:"understanding-actions",level:4},{value:"Callbacks",id:"callbacks",level:5},{value:"Commands",id:"commands",level:5},{value:"Suites",id:"suites",level:3},{value:"Variations",id:"variations",level:3},{value:"Examples",id:"examples",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"flexibench",children:"FlexiBench"}),"\n",(0,i.jsx)(n.p,{children:"FlexiBench is a flexible benchmarking library for JavaScript and TypeScript. It is designed to be simple to use, but also powerful and flexible. It is inspired by common testing framework APIs, and aims to provide a similar experience for benchmarking."}),"\n",(0,i.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"npm install --save-dev flexi-bench\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"yarn add --dev flexi-bench\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pnpm add --save-dev flexi-bench\n"})}),"\n",(0,i.jsx)(n.h2,{id:"features",children:"Features"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#variations",children:"Variations"}),": Run the same benchmark with different configurations."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#setup-and-teardown",children:"Setup and Teardown"}),": Run setup and teardown code before and after the benchmark."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#commands",children:"Commands"}),": Run simple commands as benchmarks."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,i.jsx)(n.h3,{id:"runner-api",children:"Runner API"}),"\n",(0,i.jsx)(n.p,{children:"The runner API is the simplest way to run benchmarks. It allows running a single benchmark or a suite of benchmarks."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { suite, benchmark, setup, teardown } = require('flexi-bench');\n\n// A `suite` call at the top level will be evaluated as a whole suite.\nsuite('My Suite', () => {\n  // Nested `benchmark` calls will not be evaluated until the parent `suite` is evaluated.\n  benchmark('My Benchmark', (b) => {\n    setup(() => {\n      // some setup to run before the entire benchmark\n    });\n\n    teardown(() => {\n      // some teardown to run after the entire benchmark\n    });\n\n    b.withAction(() => {\n      // some action to benchmark\n    });\n  });\n});\n\n// Top-level `benchmark` calls will be evaluated immediately.\nbenchmark('My Benchmark', (b) => {\n  b.withIterations(10).withAction(() => {\n    // some action to benchmark\n  });\n});\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Within the callbacks for each ",(0,i.jsx)(n.code,{children:"suite"})," or ",(0,i.jsx)(n.code,{children:"benchmark"})," you can utilize the builder API for full customization of the benchmark. Variations can either be added directly via the builder API, or by nesting a ",(0,i.jsx)(n.code,{children:"variation"})," call within the ",(0,i.jsx)(n.code,{children:"benchmark"})," call, or at the ",(0,i.jsx)(n.code,{children:"suite"})," level to apply the variation to all benchmarks in the suite."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { suite, benchmark, variation } = require('flexi-bench');\n\nsuite('My Suite', () => {\n  benchmark('My Benchmark', (b) => {\n    b.withIterations(10).withAction(() => {\n      // some action to benchmark\n    });\n\n    variation('with NO_DAEMON', (v) =>\n      v.withEnvironmentVariable('NO_DAEMON', 'true'),\n    );\n  });\n});\n"})}),"\n",(0,i.jsx)(n.h3,{id:"basic-benchmarks",children:"Basic Benchmarks"}),"\n",(0,i.jsx)(n.p,{children:"More detailed documentation will come soon. For now, here is a simple example:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { Benchmark } = require('flexi-bench');\n\nconst benchmark = new Benchmark('My Benchmark', {\n  iterations: 10,\n  action: () => {\n    // some action to benchmark\n  },\n});\n\nawait benchmark.run();\n"})}),"\n",(0,i.jsx)(n.p,{children:"Most options for the benchmark can also be provided by a builder API:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { Benchmark } = require('flexi-bench');\n\nconst benchmark = new Benchmark('My Benchmark')\n  .withIterations(10)\n  .withSetup(() => {\n    // some setup to run before the entire benchmark\n  })\n  .withAction(() => {\n    // some action to benchmark\n  });\n"})}),"\n",(0,i.jsx)(n.h4,{id:"setup-and-teardown",children:"Setup and Teardown"}),"\n",(0,i.jsxs)(n.p,{children:["Some benchmarks will require some work before the benchmark to setup the environment, and some work after the benchmark to clean up. This can be done with the ",(0,i.jsx)(n.code,{children:"setup"}),"/",(0,i.jsx)(n.code,{children:"setupEach"})," and ",(0,i.jsx)(n.code,{children:"teardown"}),"/",(0,i.jsx)(n.code,{children:"teardownEach"})," methods:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"benchmark('My Benchmark', (b) => {\n  setup(() => {\n    // some setup to run before the entire benchmark\n  });\n\n  setupEach(() => {\n    // some setup that is ran before each iteration of the benchmark\n  });\n\n  teardown(() => {\n    // some teardown to run after the entire benchmark\n  });\n\n  teardownEach(() => {\n    // some teardown that is ran after each iteration of the benchmark\n  });\n});\n"})}),"\n",(0,i.jsx)(n.p,{children:"These can also be set using the builder API:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { Benchmark } = require('flexi-bench');\n\nconst benchmark = new Benchmark('My Benchmark')\n  .withIterations(10)\n  .withSetup(() => {\n    // some setup to run before the entire benchmark\n  })\n  .withSetupEach(() => {\n    // some setup that is ran before each iteration of the benchmark\n  })\n  .withTeardown(() => {\n    // some teardown to run after the entire benchmark\n  })\n  .withTeardownEach(() => {\n    // some teardown that is ran after each iteration of the benchmark\n  });\n"})}),"\n",(0,i.jsx)(n.h4,{id:"understanding-actions",children:"Understanding Actions"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"action"})," for a benchmark provides the actual event that is being benchmarked. FlexiBench can currently benchmark 2 types of actions:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Callbacks"}),"\n",(0,i.jsx)(n.li,{children:"Commands"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["An ",(0,i.jsx)(n.code,{children:"action"})," can be specified via the ",(0,i.jsx)(n.code,{children:"action"})," property of the ",(0,i.jsx)(n.code,{children:"benchmark"})," or ",(0,i.jsx)(n.code,{children:"variation"})," constructor, or via ",(0,i.jsx)(n.code,{children:".withAction"})," on the builder API. Actions specified on the running ",(0,i.jsx)(n.code,{children:"variation"})," will override the action specified on the parent ",(0,i.jsx)(n.code,{children:"benchmark"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["For example, the following code will run the ",(0,i.jsx)(n.code,{children:"action"})," specified on the ",(0,i.jsx)(n.code,{children:"variation"}),", and not the ",(0,i.jsx)(n.code,{children:"action"})," specified on the ",(0,i.jsx)(n.code,{children:"benchmark"}),". This would result in the output ",(0,i.jsx)(n.code,{children:"bar"})," being printed 10 times, instead of ",(0,i.jsx)(n.code,{children:"foo"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { Benchmark } = require('flexi-bench');\n\nconst benchmark = new Benchmark('My Benchmark', {\n  iterations: 10,\n  action: () => {\n    console.log('foo');\n  },\n}).withVariation('with NO_DAEMON', (v) =>\n  v.withAction(() => {\n    console.log('bar');\n  }),\n);\n"})}),"\n",(0,i.jsx)(n.h5,{id:"callbacks",children:"Callbacks"}),"\n",(0,i.jsxs)(n.p,{children:["If the process you are benchmarking is available as a JavaScript function, you can pass it directly to the ",(0,i.jsx)(n.code,{children:"action"})," property or execute it within the ",(0,i.jsx)(n.code,{children:"action"})," callback. For example, if you are benchmarking a function that sorts an array, you can do the following:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { benchmark, setup } = require('flexi-bench');\n\nbenchmark('My Benchmark', (b) => {\n  let array;\n\n  setup(() => {\n    array = Array.from({ length: 1000 }, () => Math.random());\n  });\n\n  b.withIterations(10).withAction(() => {\n    array.sort();\n  });\n});\n"})}),"\n",(0,i.jsx)(n.h5,{id:"commands",children:"Commands"}),"\n",(0,i.jsxs)(n.p,{children:["If the process you are benchmarking is not available as a JavaScript function, you can run it as a command. This can be done by passing a string to the ",(0,i.jsx)(n.code,{children:"action"})," property. For example, if you are benchmarking the runtime of a cli command, you can do the following:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { Benchmark } = require('flexi-bench');\n\nconst benchmark = new Benchmark('My Benchmark', {\n  iterations: 10,\n  action: 'echo \"Hello, World!\"',\n});\n\nawait benchmark.run();\n"})}),"\n",(0,i.jsxs)(n.p,{children:["While it would be possible to write an action that runs a command using ",(0,i.jsx)(n.code,{children:"child_process"})," methods, using the syntactic sugar provided by flexi-bench is more convenient and provides a few benefits."]}),"\n",(0,i.jsxs)(n.p,{children:["Utilizing the syntactic sugar also means that flexi-bench is aware that you are indeed running a command. This sounds obvious, but opens up some neat possibilities since we are running the command from within flexi-bench. For example, we can add variations based on tailoring CLI options which would not be possible if you ran your command directly using ",(0,i.jsx)(n.code,{children:"child_process"})," methods on your own."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { Benchmark } = require('flexi-bench');\n\nconst benchmark = new Benchmark('My Benchmark', {\n  iterations: 10,\n  action: 'echo',\n})\n  .withVariation('with argument', (v) => v.withArgument('Hello, Earth!'))\n  .withVariation('with argument', (v) => v.withArgument('Hello, Mars!'));\n\nawait benchmark.run();\n"})}),"\n",(0,i.jsx)(n.p,{children:"When running commands via the syntactic sugar, the command is invoked with a function similar to below:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"const child = spawn(action, variation.cliArgs, {\n  shell: true,\n  windowsHide: true,\n});\nchild.on('exit', (code) => {\n  if (code === 0) {\n    resolve();\n  } else {\n    reject(`Action failed with code ${code}`);\n  }\n});\n"})}),"\n",(0,i.jsx)(n.p,{children:"For more information on the simple command API, see the example: ./examples/simple-command.ts"}),"\n",(0,i.jsx)(n.h3,{id:"suites",children:"Suites"}),"\n",(0,i.jsx)(n.p,{children:"A suite is a collection of benchmarks that can be run together:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { Benchmark, Suite } = require('flexi-bench');\n\nconst suite = new Suite('My Suite')\n  .addBenchmark(\n    new Benchmark('My Benchmark 1', {\n      iterations: 10,\n      action: () => {\n        // some action to benchmark\n      },\n    }),\n  )\n  .addBenchmark(\n    new Benchmark('My Benchmark 2', {\n      iterations: 10,\n      action: () => {\n        // some action to benchmark\n      },\n    }),\n  );\n"})}),"\n",(0,i.jsx)(n.p,{children:"Suites can also be created using the runner API:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { suite, benchmark } = require('flexi-bench');\n\nsuite('My Suite', () => {\n  benchmark('My Benchmark 1', (b) => {\n    b.withIterations(10).withAction(() => {\n      // some action to benchmark\n    });\n  });\n\n  benchmark('My Benchmark 2', (b) => {\n    b.withIterations(10).withAction(() => {\n      // some action to benchmark\n    });\n  });\n});\n"})}),"\n",(0,i.jsx)(n.h3,{id:"variations",children:"Variations"}),"\n",(0,i.jsx)(n.p,{children:"Variations allow running the same benchmark with different configurations:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { Benchmark, Variation } = require('flexi-bench');\n\nconst benchmark = new Benchmark('My Benchmark', {\n  iterations: 10,\n  action: () => {\n    // some action to benchmark\n  },\n}).withVariation('with NO_DAEMON', (v) =>\n  v.withEnvironmentVariable('NO_DAEMON', 'true'),\n);\n"})}),"\n",(0,i.jsx)(n.p,{children:"Variations can do most things that the main benchmark can do, including having their own setup and teardown functions, or even a custom action."}),"\n",(0,i.jsxs)(n.p,{children:["Some helper functions are provided on the ",(0,i.jsx)(n.code,{children:"Variation"})," class to make it easier to set up variations:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { Benchmark, Variation } = require('flexi-bench');\n\nconst benchmark = new Benchmark('My Benchmark', {\n  iterations: 10,\n  action: () => {\n    // some action to benchmark\n  },\n}).withVariations(\n  // Adds 4 variations with all possible combinations of the given environment variables\n  Variation.FromEnvironmentVariables([\n    ['NO_DAEMON', ['true', 'false']],\n    ['OTHER_VAR', ['value1', 'value2']],\n  ]),\n);\n"})}),"\n",(0,i.jsx)(n.p,{children:"Variations can also be added to suites. Variations added to a suite will be applied to all benchmarks in the suite."}),"\n",(0,i.jsx)(n.p,{children:"For example, the below suite would run each benchmark with 'NO_DAEMON' set to true, and then with 'OTHER_VAR' set to 'value1' for a total of 4 benchmark runs in the suite:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-javascript",children:"const { Benchmark, Suite, Variation } = require('flexi-bench');\n\nconst suite = new Suite('My Suite')\n  .addBenchmark(\n    new Benchmark('My Benchmark 1', {\n      iterations: 10,\n      action: () => {\n        // some action to benchmark\n      },\n    }),\n  )\n  .addBenchmark(\n    new Benchmark('My Benchmark 2', {\n      iterations: 10,\n      action: () => {\n        // some action to benchmark\n      },\n    }),\n  )\n  .withVariation('with NO_DAEMON', (v) =>\n    v.withEnvironmentVariable('NO_DAEMON', 'true'),\n  )\n  .withVariation('with OTHER_VAR', (v) =>\n    v.withEnvironmentVariable('OTHER_VAR', 'value1'),\n  );\n"})}),"\n",(0,i.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,i.jsx)(n.p,{children:"See examples folder."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"./examples/benchmark.ts is the motivation for this project. It benchmarks the performance of Nx commands with and without a daemon."}),"\n",(0,i.jsx)(n.li,{children:"./examples/performance-observer.ts is a simple example of how to use the PerformanceObserver API to measure the performance of a function."}),"\n",(0,i.jsx)(n.li,{children:"./examples/simple-command.ts demonstrates how to benchmark a simple command."}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},3023:(e,n,a)=>{a.d(n,{R:()=>c,x:()=>s});var i=a(3696);const t={},r=i.createContext(t);function c(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:c(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);